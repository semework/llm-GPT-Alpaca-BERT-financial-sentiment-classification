{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8aace85",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;color:Blue\">\n",
    "    <h2> Large Language Model (LLM) sentiment analysis of financial news using Alpaca, BERT and ChatGPT</h2>\n",
    "</div>\n",
    "\n",
    "#### An experiment  with the fascinating potential of large language models to efficiently classify short news summaries and headlines into 'positive', 'neutral' and 'negative' sentiments. Here we use Alpaca, BERT and ChatGPT to:\n",
    "1. import news headings and summaries for specific stock symbols\n",
    "2. use the language (NLP) model Bidirectional Encoder Representations from Transformers (BERT) to tokenize and classify the news data into sentiments \n",
    "3. classify the same news data using OpenAI's gpt-3.5 to do the same "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609dd9c7",
   "metadata": {},
   "source": [
    "#### Step 0 - Install the necessary libraries - uncomment and run the following cells if they are not already installed. This is followed by importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc4887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip -q install alpaca-trade-api alpaca-py transformers openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124a9493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain sometimes has issues with dependencies and it is recommended to do the following:\n",
    "# !pip -q install langchain --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a46f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 16:37:31.605201: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_tagging_chain, create_tagging_chain_pydantic\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "from alpaca_trade_api import REST, Stream\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, AutoModelForSeq2SeqLM\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b68c90",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;color:red\">\n",
    "    <h2>1 - Import keys saved in your environment</h2>\n",
    "</div>\n",
    "\n",
    "#### Most APIs provide a security option to ensure that you can store your authentication details in environment variables. This enables you:\n",
    "1. to authenticate your logins and code tracking in code depos such as GitHub\n",
    "2. in addition to #1, to control your privileges such as OpenAI's tokens\n",
    "3. to protect yourself from inadvertently exposing your secret IDs and keys in any environment such as live trading platforms such as Alpaca\n",
    "#### For best practices read:\n",
    "1. OpenAI's advice: https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\n",
    "1. Alapaca: https://medium.com/software-engineering-learnings/algorithmic-trading-with-alpaca-and-python-c81bad480053\n",
    "3. General: https://www.twilio.com/blog/how-to-set-environment-variables-html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05dee8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys imported\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "API_KEY = os.getenv(\"APCA_API_KEY_ID\")\n",
    "API_SECRET = os.getenv(\"APCA_API_KEY_SECRET\")\n",
    "print('keys imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b836984",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;color:red\">\n",
    "    <h2> 2 - Setup your llm model and construct a pydantic base model</h2>\n",
    "</div>\n",
    "\n",
    "##### Pydantic defines objects via models (classes which inherit from pydantic.BaseModel).\n",
    "More info here: https://docs.pydantic.dev/latest/usage/models/ which states:\n",
    "- These models are similar to Python's dataclasses with some differences that streamline certain workflows related to validation, serialization, and JSON schema generation. Untrusted data can be passed to a model and, after parsing and validation, Pydantic guarantees that the fields of the resultant model instance will conform to the field types defined on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c9cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "class Tags(BaseModel):\n",
    "    sentiment: str = Field(..., enum=[\"positive\", \"neutral\", \"negative\"])\n",
    "\n",
    "chain = create_tagging_chain_pydantic(Tags, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b494abe",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;color:red\">\n",
    "    <h2> 3 - Prepare sentiment analysis models and pipeline</h2>\n",
    "</div>\n",
    "\n",
    "#### Approach and cautionary note:\n",
    "- we will use a fine-tuned (trained for financial news) Hugging Face model (BERT) to analyze the article's headline and summary sentiment\n",
    "- initial model downloads might take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9a3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenizer = AutoTokenizer.from_pretrained(\"ahmedrachid/FinancialBERT-Sentiment-Analysis\")\n",
    "sent_model = AutoModelForSequenceClassification.from_pretrained(\"ahmedrachid/FinancialBERT-Sentiment-Analysis\")\n",
    "sent_nlp = pipeline(\"sentiment-analysis\", model=sent_model, tokenizer=sent_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c8a96",
   "metadata": {},
   "source": [
    "#### Next, create an alpaca client, choose stock tickers and decide how many days of news to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e6478f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_client = REST(API_KEY, API_SECRET)\n",
    "tickers = [\"GOOG\",\"AAPL\",\"YAH\",'MSFT','AAPL','CNN','KHC']\n",
    "number_of_days = 10\n",
    "start_date = date.today() - timedelta(number_of_days)\n",
    "end_date = date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d28d73",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;color:red\">\n",
    "    <h2> 4 - Create a functions to classify individual news and calculate an average sentiment per ticker and to process all tickers</h2>\n",
    "</div>\n",
    "\n",
    "#### Important considerations:\n",
    "- more recent news might be more relevant\n",
    "- the sentiment confidence also gives us a clue how certain the algorithm is about its classification\n",
    "\n",
    "#### Approach:\n",
    "- weigh recent news more heavily (straightforward linear increase, going from old to new - although there can be many variations of this approach such as inverted/hyperbolic, linear-with-noise, etc. approaches)\n",
    "- use sentiment confidence to adjust our weights. i.e. multiply recency score with the score\n",
    "- the function ```sentiment_to_weighed``` takes care of the weighing\n",
    "- the function ```sentiment_analysis``` takes in a list and tickers and returns a weighed sentiment per ticker\n",
    "- since OpenAI's tocken allotments deplete quickly, a few lines in  ```sentiment_analysis``` are commented out and a flag is given. Uncomment them if you have enough tokens left (after changing ```do_llm``` flag to \"1\". Note that llm sentiment classification is slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe27bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_to_weighed(sent_labels, sent_scores):\n",
    "    if len(sent_labels):\n",
    "        len_news = len(sent_labels)\n",
    "        sentiment_values = [0.9 if x == 'positive' else 0.5 if x == 'neutral' else 0.3 \n",
    "                                 for x in sent_labels.values]*sent_scores\n",
    "        sent_weights = np.array(list(reversed(np.arange(0.1, (len_news)/len_news+0.1, 1/len_news))))\n",
    "        sent_scored_weights = sentiment_values*sent_weights \n",
    "        mean_sent_scored = np.average(sentiment_values, weights = sent_scored_weights)\n",
    "        sent_weighed = ['positive' if mean_sent_scored >= 0.65 else 'neutral' \n",
    "                        if (mean_sent_scored >= 0.3 and mean_sent_scored <0.65) \n",
    "                        else 'negative'][0]\n",
    "    else:\n",
    "        print('no news')\n",
    "        sent_weighed = 'neutral'\n",
    "    return sent_weighed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0114160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(news_sents, tickers, do_llm):\n",
    "    news_sents_columns = ['ticker','sentiment']\n",
    "    for t in tickers:\n",
    "        news_sentiments = pd.DataFrame()\n",
    "        news = rest_client.get_news(t, start_date, end_date)\n",
    "        news1 = pd.DataFrame({\n",
    "            'summary': [x.summary for x in news],\n",
    "            'headline': [x.headline for x in news],\n",
    "    #         uncomment the following to verify that news are sorted most recent first\n",
    "    #         created_at': [x.created_at for x in news], \n",
    "        })\n",
    "        news_sentiments['headline&summary'] = news1.summary + news1.headline\n",
    "        sentiment = [sent_nlp([x])[0] for x in news_sentiments['headline&summary']]\n",
    "        \n",
    "        if do_llm:\n",
    "            news_sents_columns = ['ticker','sentiment', 'llm_sentiment']\n",
    "            llm_sentiment = [chain.run(x).sentiment for x in positions['headline&summary']]\n",
    "            news_sentiments['llm_label'] = [llm_sentiment[x] for x in range(0, len(llm_sentiment))]\n",
    "            # to save time, we use a score of 1 for llms - although this can be done exactly as BERT\n",
    "            llm_scores = [1]*len(llm_sentiment)\n",
    "            sent_llm_wighed = sentiment_to_weighed(news_sentiments['llm_label'], llm_scores)\n",
    "            \n",
    "        news_sentiments['label'] = [sentiment[x]['label'] for x in range(0, len(sentiment))]\n",
    "        news_sentiments['score'] = [sentiment[x]['score'] for x in range(0, len(sentiment))]\n",
    "        sent_wighed = sentiment_to_weighed(news_sentiments['label'], news_sentiments['score'])\n",
    "        news_sentiments['ticker'] = t\n",
    "        \n",
    "        # peek at the results - to save time and visual space, show only the first ticker resuls\n",
    "        if t == tickers[0]:\n",
    "            print(news_sentiments)\n",
    "        #uncomment the following line to see dataframes for each ticker and news article\n",
    "#         print(news_sentiments)\n",
    "        \n",
    "        if do_llm:\n",
    "            news_sents.append([t, sent_wighed, sent_llm_wighed])\n",
    "        else:\n",
    "            news_sents.append([t, sent_wighed])\n",
    "            \n",
    "    news_sents = pd.DataFrame(news_sents)\n",
    "    news_sents.columns = news_sents_columns\n",
    "    return news_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29f96e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    headline&summary     label     score  \\\n",
      "0   A new player has joined the AI chatbot race, ...  positive  0.950089   \n",
      "1  U.S. Sen. Bernie Sanders has made waves over t...   neutral  0.999205   \n",
      "2  Google Play Changes Policy On Tokenized Digita...   neutral  0.999427   \n",
      "3  'The Roku Channel Is Now Streaming On Google T...   neutral  0.990214   \n",
      "4  Wall Street JournalDisney Considers Different ...   neutral  0.999546   \n",
      "5  Alphabet Inc (NASDAQ: GOOG) (NASDAQ: GOOGL) Go...   neutral  0.997340   \n",
      "6  George Hotz discusses the unique decision-maki...   neutral  0.999708   \n",
      "7  Elon Musk&#39;s comments on chatGPT&#39;s hall...  positive  0.700688   \n",
      "8  Each trading day features hundreds of headline...   neutral  0.999608   \n",
      "9  To gain an edge, this is what you need to know...   neutral  0.961198   \n",
      "\n",
      "  ticker  \n",
      "0   GOOG  \n",
      "1   GOOG  \n",
      "2   GOOG  \n",
      "3   GOOG  \n",
      "4   GOOG  \n",
      "5   GOOG  \n",
      "6   GOOG  \n",
      "7   GOOG  \n",
      "8   GOOG  \n",
      "9   GOOG  \n",
      "no news\n",
      "no news\n"
     ]
    }
   ],
   "source": [
    "news_sents = []\n",
    "do_llm = 0\n",
    "sentiments_df = sentiment_analysis(news_sents, tickers, do_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab86a76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YAH</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KHC</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker sentiment\n",
       "0   GOOG   neutral\n",
       "1   AAPL  positive\n",
       "2    YAH   neutral\n",
       "3   MSFT  positive\n",
       "4   AAPL  positive\n",
       "5    CNN   neutral\n",
       "6    KHC   neutral"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdcc959",
   "metadata": {},
   "source": [
    "### Article Summarization\n",
    "After importing financial news for various tickers using Alpaca, a combination of Google's BERT and OpenAI's GPT was used to provide average sentiments. Thanks to the greate architects and trainers of the models, implementing the Hugging Face Transformers library is relatively easy. OpenAI's GPT llm model:\n",
    "1. was slow \n",
    "2. it was not specifically trained for financial news\n",
    "3. can not be run for large tokes due to specific quotas\n",
    "These facts made it impossible to do a direct comparisons at this time but the given functions can be used to do so in a different approach/time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ff721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
